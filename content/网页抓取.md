# 网页抓取(爬虫)

## 1.相关python库

requests

Beautiful Soup4

lxml

re

time



## 2.例子

爬取网站新闻标题

```python
import requests        #导入requests包
from bs4 import BeautifulSoup
url='http://www.cntour.cn/'                  #设定要爬的网页
#设置表头，让对方认为是浏览器在访问
headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36 Edg/92.0.902.84'}
strhtml=requests.get(url,headers)                    #设定strhtml为get到的网页
soup=BeautifulSoup(strhtml.text,'lxml')      #利用lxml解析器得到网页内容
#选择器选择要爬取的内容
##main > div > div.mtop.firstMod.clearfix > div.centerBox > ul.newsList > li:nth-child(1) > a
data = soup.select('#main>div>div.mtop.firstMod.clearfix>div.centerBox>ul.newsList>li>a')
print(data)

for item in data:
    result={
        'title':item.get_text(),
        'link':item.get('href')
    }
    print(result)

import re
for item in data:
    result={
        "title":item.get_text(),
        "link":item.get('href'),
        #这里使用 re 库的 findall 方法，第一个参数表示正则表达式，第二个参数表示要提取的文本
        'ID':re.findall('\d+',item.get('href')) #\d匹配数字 +匹配前一个字符1次或多次
    }
print(result)
```

